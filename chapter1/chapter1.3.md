=# 1. SQL 처리 과정과 I/O

## 1.3 데이터 저장 구조 및 I/O 메커니즘

### 1.3.1 SQL이 느린 이유

1. SQL이 느린 이유

- SQL 쿼리가 느린 주된 이유는 **디스크 I/O(입출력)** 이다. 
    - 디스크 I/O 과정에서 **프로세스가 CPU를 반환하고 대기(Waiting)** 하는 현상이 발생하기 때문이다.

- 이는 데이터베이스 시스템이 CPU 자원을 효율적으로 사용하기 위한 정상적인 메커니즘이지만, I/O 대기가 너무 길어지면 사용자 체감 성능은 저하된다.

- 데이터베이스(DBMS)는 필요한 데이터를 **메모리(Buffer Cache)** 에 보관하려고 하지만, 메모리가 부족하거나 처음 접근하는 데이터는 반드시 디스크에서 읽어와야 한다.
    - 이때 디스크 I/O Call이 수반하는 엄청난 속도 차이 때문에 성능 병목이 발생한다.

2. 디스크 I/O가 느린 이유

| 구분 | 메모리 (RAM) | 디스크 (HDD/SSD) |
|---|---|---|
| 속도 | 매우 빠름 (전기적 신호) | 상대적으로 매우 느림 (물리적 작동 수반) |

- 컴퓨터 부품 중에서 CPU는 빛의 속도로 빠르지만, 디스크(HDD/SSD)는 달팽이처럼 느리다.

- 만약 프로세스가 데이터를 다 읽어올 때까지 CPU를 계속 붙잡고 있다면, CPU는 아무것도 못 하고 멍하니 기다려야 한니다. (이를 **'Blocking'** 이라고 함)

- 시스템 전체 효율을 높이기 위해, **"느린 작업(I/O)을 시켜놓았으면, CPU는 일단 다른 급한 일부터 처리해라!"** 라는 것이 이 구조의 핵심 원리이다.

3. 프로세스와 CPU '대기' (Waiting State)

| 단계 | 상태 | 활동 내용 |
|---|---|---|
| 1단계 | Running (실행) | 프로세스가 CPU를 잡고 쿼리를 계산 중 |
| 2단계 | I/O 요청 | "디스크에서 데이터 좀 읽어와!"라고 명령 |
| 3단계 | Waiting (대기) | CPU를 즉시 반환하고 데이터가 올 때까지 대기 줄로 이동 |
| 4단계 | Switching (교체) | 노는 CPU에 다른 프로세스가 할당되어 작업 시작 |

- 이 메커니즘은 CPU를 효율적으로 사용하기 위함이지만, I/O 요청이 많고 디스크 응답 시간이 길수록 프로세스가 대기 상태로 머무는 총 시간이 증가한다.

	> 💡 결론 : SQL 쿼리를 완료하는 데 걸리는 시간(응답 시간)은 "CPU를 사용하는 시간"보다 "디스크 I/O 완료를 기다리는 시간(Wait Time)" 이 압도적으로 길기 때문이다.

4. 성능 저하 해결의 핵심

- SQL 튜닝은 결국 I/O 대기 시간을 최소화하는 것에 초점을 맞춘다.
    - 인덱스 활용
        - 쿼리가 테이블 전체를 읽지 않고 필요한 일부 데이터만 디스크에서 읽도록 유도하여 I/O 횟수를 줄인다.(논리적 I/O 감소)	
    - 캐싱 최적화 	
        - 메모리 버퍼 캐시 크기를 늘려 디스크 접근 없이 메모리에서 데이터를 바로 가져오는 비율을 높인다.(물리적 I/O 감소)		
    - 하드웨어 개선
        - 더 빠른 디스크(NVMe SSD 등)를 도입하거나 I/O 대역폭을 확장하여 I/O 요청 자체의 처리 속도를 높인다.

### 1.3.2 데이터베이스 저장 구조

#### 데이터베이스 저장 구조

![img](https://github.com/devfrom2ne1/kind_sql_tuning/blob/main/images/TableSpace.png)

- 도서관을 데이터베이스에 비유한다면?
    - `테이블스페이스` : 도서관의 '구역' 하나
    - `세그먼트` : 구역 내에 '책장' 하나
    - `익스텐트` : 책장에 추가된 '선반' 한 칸
    - `블록` : 책 한권에 들어있는 '종이' 한 장

#### 한 테이블의 row들이 어떻게 저장될까?

A테이블 안에 1~1000번까지의 row가 있다면, 어떻게 저장되는 걸까?

1. 테이블 = 세그먼트 (하나의 주머니)
    - 1,000번까지의 로우는 모두 '같은 테이블' 소속이다? 
    - 그렇다면 이 데이터들은 모두 하나의 세그먼트(해당 테이블의 세그먼트) 안에 담긴다.

    > 1,000개의 로우를 쪼개서 여러 세그먼트에 나누는 것이 아니라, 세그먼트라는 큰 봉투 하나에 1,000개의 로우가 다 들어가는 것입니다. 세그먼트는 테이블 그 자체이다.

2. 세그먼트 안에서 익스텐트로 쪼개기 (공간 나누기)
    - 세그먼트(봉투) 안에서 데이터가 늘어날 때, 공간을 관리하기 위해 익스텐트(주머니) 단위로 쪼개서 담는다.
    - `예시 상황` (익스텐트 하나에 200 로우가 들어간다고 가정)
       * 익스텐트 #1 : 1~200번 로우 저장 (1번 데이터 파일에 위치)
       * 익스텐트 #2 : 201~400번 로우 저장 (2번 데이터 파일에 위치)
       * 익스텐트 #3 : 401~600번 로우 저장 (3번 데이터 파일에 위치)
       * ... : 이런 식으로 익스텐트 단위로 쪼개져서 여러 데이터 파일에 분산될 수 있다.

3. 익스텐트 안에서 블록으로 쪼개기 (실제 방)
    - 하나의 익스텐트(200개 로우) 안에서도 더 작은 단위인 데이터 블록으로 또 나뉜다.
    - `예시 상황`
        * 블록 #1 : 1~10번 로우
        * 블록 #2 : 11~20번 로우
        * ...  : 이렇게 블록들이 모여 하나의 익스텐트를 형성한다.
    
    > 익스텐트에 넣나? 네, 세그먼트라는 큰 틀 안에서 실제 데이터는 여러 개의 익스텐트로 나뉘어 저장된다. 그리고 그 익스텐트들은 여러 데이터 파일에 흩어져 존재할 수 있다.

#### 데이터를 저장하는 과정

https://mblogthumb-phinf.pstatic.net/MjAyMTAzMTVfNTcg/MDAxNjE1ODExNzk2NzQ4.G_ZMfd7xNbtpkQzGwf9kWO5F3IWlnvZ59Ozuiw-Ukvgg.4SCgfiECAivu93LvMlTs9x58uYg3wPI2FaSvlSC3gBAg.PNG.nayoon210/image.png?type=w800

- 🏗️ 구조적 계층 요약 (위에서 아래로)
     * 세그먼트 (전체 주황색 칸들의 모임) : 1~1,000번 로우 전체를 품고 있는 논리적인 실행 단위
     * 익스텐트 (중괄호로 묶인 덩어리) : 세그먼트가 공간을 확보한 뭉치입니다. 이 단계에서 데이터가 파일별로 쪼개져 담길 수 있다.
     * 데이터 블록 (주황색 네모 한 칸) : 실제 로우들이 옹기종기 모여 있는 최소 공간이다.

1. 데이터가 어느 '테이블스페이스'에 들어가는지 확인한다.
    * 테이블스페이스는 세그먼트를 담는 콘테이너이다.
    * 테이블스페이스는 디스크 상의 물리적인 OS파일인 여러 개의 데이터파일로 구성된다.

2. 해당 테이블의 실제 저장 덩어리인 '세그먼트'를 찾아간다. 
    * 세그먼트
        * 세그먼트는 데이터가 실제로 담기는 논리적 객체이다.
        * 데이터베이스는 용도에 따라 세그먼트를 나눈다.
        * 테이블, 인덱스, 파티션, LOB 등의 오브젝트가 그 종류이다.
        * 만약, 기존 할당된 공간이 꽉 찼다면 DB는 테이블스페이스로부터 새로운 '익스텐트' 공간을 추가로 할당 받는다.

    * 익스텐트
        * 익스텐트는 세그먼트 내 공간을 확장하는 단위이다.
        * 추상적 단위가 아니라 '연속된 블록들의 집합'이라는 실체를 가진다.
        * 매번 최소 단위인 '블록'을 추가하는 것은 비효율적이기 때문에, '익스텐트'단위로 관리하는 것이다.
        * 익스텐트 내에 있는 데이터블록들은 가급적 연속적으로 배치되기 때문에, 읽기 속도가 빨라질 수 있다.
        * 하나의 익스텐트는 하나의 테이블이 독점한다.
        * 익스텐트끼리는 연속된 공간이 아니다.

3. DB는 비어있는 '데이터블록'을 찾아 그 안에 실제 데이터를 기록한다.
    * 데이터 블록
        * 데이터 블록은 실제 데이터를 저장되는 최소 단위의 공간이다.
        * 즉, 하드디스크 섹터들을 모아 만든 논리적인 방이다.
        * 데이터블록은 '공통헤더 + 여유공간 + 데이터공간' 세 부분으로 나뉜다.
        * 한 블록은 하나의 테이블이 독점한다.

4. 실체 하드디스크의 '데이터파일'에 물리적으로 기록한다. 
    * 메모리(RAM)에 임시로 머물던 데이터를 하드디스크(HDD/SDD)라는 영구 저장소에 실제로 옮겨 적는 과정이다.

    * 메모리가 디스크보다 수만 배 빠르기 때문에, 먼저 메모리에 있는 데이터 블록에 내용을 임시로 저장해두는 것이다.
        * 이때, 메모리에만 있고 디스크에 아직 반영되지 않은 블록을 '더티 블록' 이라고 한다.
    
    * 데이터가 바뀌면, 로그파일에 백업메모(Redo Log)를 재빠르게 남긴다.
        * 로그 기록은 디스크에 쓰기 전 전원이 꺼지는 경우에 복구하기 위해 사용한다.
    
    * 메모리에 모여 있던 '더티 블록'들을 실제 '데이터파일'에 덮어쓴다.

#### 오라클에서 세그먼트에 할당된 인스텐트 목록 조회하는 방법

```sql
select segment_type, tablespace_name, extent_id, file_id, block_id, blocks 
from dba_extents
where owner = USER
and segment_name = 'MY_SEGMENT'
order by extent_id;
```

### 1.3.3 블록 단위 I/O

DBMS는 `데이터 블록` 단위로 데이터를 읽고 쓴다. (파일단위X)
- 특정 레코드 하나만 읽고 싶어도, 해당 블록을 통째로 읽는 구조임

#### 오라클 데이터베이스 블록 사이즈를 확인하는 방법

```sql
-- 방법(1)
show parameter block_size

-- 방법(2)
select value from v$parameter where name = 'db_block_size';
```

### 1.3.4 시퀀셜 액세스 vs 랜덤 액세스

테이블 또는 인덱스블록을 액세스 하는 방법은 `시퀀셜 액세스` 와 `랜덤 액세스` 두 가지가 있음

1. 시퀀셜 액세스
    - 논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방식

2. 랜덤 액세스
    - 한 블록씩 접근하는 방법 

### 1.3.5 논리적 I/O vs 물리적 I/O

#### DB 버퍼캐시란

- 라이브러리 캐시 : SQL, 실행계획, 함수, 프로시저 등을 캐싱하는 '코드 캐시'
- DB버퍼 캐시 : 디스크에서 어렵게 읽은 데이터 블록을 캐싱해 두는 '데이터 캐시'
    - 서버 프로세스와 데이터파일 사이에 있어서, 데이터 블록을 읽을 때 'DB 버퍼캐시'를 먼저 탐색함
    - 공유 메모리 영역이므로, 같은 블록을 읽는 다른 프로세스도 득을 본다. 

#### 논리적 I/O vs 물리적 I/O

- 논리적 I/O : SQL문을 처리하는 과정에 메모리 버퍼캐시에서 발생한 총 블록 I/O
    - 블록 읽기 요청
    - 메모리 I/O : 전기적신호, 빠름
    - 전기적 신호

- 물리적 I/O : 디스크에서 발생한 총 블록 I/O
    - 버퍼캐시 Miss 
        - SQL 처리 도중 읽어야 할 블록을 버퍼캐시에서 찾지 못할 때만 디스크를 액세스함
    - 디스크 I/O
    - 액서스 Arm : 물리적작용, 느림, 디스크 경합 심할때는 더 느림

#### 왜 논리적 I/O 인가?

- (논리적 I/O 횟수) = (DB 버퍼캐시에서 블록을 읽은 횟수)
- (물리적 I/O 횟수) = (DB 버퍼캐시에서 못찾아서 디스크에서 읽은 블록 I/O)
- 테이블에 insert, delete 하지 않은 이상, 같은 SQL이 읽는 블록수는 같다. 논리적 I/O는 불변
- 반면, 물리적 I/O는 실행할 때마다 달라짐

#### 버퍼캐시 히트율(BCHR)

- 버퍼캐시 효율을 측정하는데 전통적으로 많이 사용해온 지표이다. 

- 전체 블록 중에서 물리적인 디스크 I/O를 수반하지 않고 곧바로 메모리에서 찾은 비율이다.
    - BCHR = ( (논리적 I/O - 물리적 I/O) / (논리적 I/O) ) * 100
    - 물리적 I/O = 논리적 I/O * (100 - BCHR)

- 온라인 트랜젝션 애플리케이션의 적정 BCHR은 99%이다. 
    - 논리적 I/O는 일정하므로, 물리적 I/O는 BCHR에 의해서 결정된다. 
    - SQL성능을 높이기 위해선 논리적 I/O 낮은 상태로 일정하게 만들어야 한다.

- 논리적 I/O를 줄이는 방법은?
    - SQL을 튜닝해서 읽는 총 블록 개수를 줄이면 된다. 

### 1.3.6 Single Block I/O vs Multiblock I/O

- 메모리 캐시에 적재되지 않은 데이터를 찾을 때, I/O Call을 통해 '디스크 -> DB버퍼캐시'로 적재하고 읽음
    - 버퍼캐시가 메모리 ?!

- 이때, I/O Call 을 하는 두 가지 방법이 있음
    - `Single Block I/O` : 적은 데이터 블록을 읽을 때, 한 번에 한 블록씩 요청해서 메모리에 적재하는 방식
    - `Multiblock I/O` : 많은 데이터 블록을 읽을 때, 같은 익스텐트의 인접한 블록을 한꺼번에 읽어서 캐시에 미리 적재하는 방식

### 1.3.7 Table Full Scan vs Index Range Scan 

- `Table Full Scan` : 테이블에 속한 블록 전체를 읽어서 데이터를 찾는 방식
- `Index Range Scan` : ROWID로 테이블 레코드를 찾아가는 방식
    - `랜덤 액세스` + `Single Block I/O`
    - 많은 데이터를 읽을 때는 불리함
    - 읽었던 블록을 반복해서 읽는 비효율이 있음

### 1.3.8 캐시탐색 메커니즘

#### 버퍼캐시 구조

DBMS는 버퍼캐시를 해시 구조로 관리함
- 버퍼캐시에서 블록을 찾을 때 해시 알고리즘으로 `버퍼 헤더`를 찾고, 거기서 얻은 포인터로 버퍼 블록을 액세스 함

#### 메모리 공유자원에 대한 액세스 직렬화

직렬화 메커니즘이 필요한 이유

- 버퍼캐시는 SGA 구성요소이므로, 버퍼캐시에 캐싱된 버퍼블록은 모두 공유자원임
- 하나의 버퍼블록을 두 개 이상 프로세스가 '동시에' 접근하면 블록 정합성 문제가 생길 수 있음
- 이떄, 공유된 자원을 한 프로세스식 순차적으로 접근하도록 하는 것이 `직렬화 메커니즘` 이다.

래치란?
- 직렬화 메커니즘(줄서기)이 가능하도록 지원하는 메커니즘이 `래치(Latch)` 이다.
- 간단하게 설명하자면, 자물쇠를 열 수 있는 키가 있는 프로세스만이 체인으로 진입할 수 있게하는 것이다. 

버퍼 Lock
- 버퍼블록 자체에도 `버퍼 Lock` 이라는 직렬화 메커니즘이 존재한다. 
- 래치를 해제한 상태로 있는 도중에 후행 프로세스가 같은 블록에 접근할 수도 있는 문제를 방지하기 위해 버퍼 Lock이 필요하다. 

